                                        # YIM
The YIM Multi-Tasking Voice-Controlled Robot project presents an innovative, voiceoperated
robotic system designed to serve as a smart assistant and service bot for diverse
applications, including classroom navigation, home automation, and safety monitoring. This
project integrates advanced voice recognition, sensor-based navigation, and IoT-enabled
automation to execute multiple tasks seamlessly via offline voice commands.

At its core, the robot employs the VC02 AI Thinker module for offline voice recognition,
converting user commands into digital signals processed by an ESP32
microcontroller (supported by an Arduino UNO for peripheral control). Key functionalities
include human-following via ultrasonic sensors, 3D motion robotic arm operations for object
handling, and magnetic tape/RFID-based classroom navigation, where the robot follows
predefined magnetic tape paths and identifies junctions using RFID tags. The system also
integrates Wi-Fi, Bluetooth-enabled home automation, allowing remote control of appliances
through relay modules.

Safety is prioritized through real-time temperature monitoring (DHT11 sensor), while obstacle
avoidance is achieved via ultrasonic sensors and adaptive rerouting algorithms. Testing
demonstrated 85-90% accuracy in voice command recognition under low-to-moderate noise,
with reliable task execution latency under 3 seconds. Future scalability includes Alexa Echo
4th Gen integration for expanded voice-controlled features, IoT based automatic application
control and monitoring.

This project bridges robotics, IoT, and human-machine interaction, offering a versatile solution
for educational, domestic, and industrial environments. Its modular design ensures adaptability,
emphasizing practicality, safety, and user-friendly operation.
Keywords: Voice-controlled robot, ESP32 microcontroller, RFID navigation, home
automation, IoT, robotic arm, offline voice recognition.
